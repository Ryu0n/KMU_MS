* train_test_split() : 학습 데이터와 테스트 데이터 분리
return : X_test, X_test, y_train, y_test

* Estimator 프로세스 : fit() -> predict()
학습(파라미터를 조정) 후 예측

* 교차 검증
고정된 학습 데이터로만 학습할 경우 오버피팅을 야기
이러한 문제를 해결하고자 다양한 학습과 평가를 진행

- K 폴드 교차 검증
from sklearn.model_selection import KFold

kfold = KFlod(n_splits=N)

for train_index, test_index in kfold.split(...):

데이터를 K개의 데이터 폴드 세트를 만들어서 N(1~K)번째 데이터 폴드 세트를 추론을 시키고 나머지는 학습

- Stratified K 폴드
from sklearn.model_selection import StratifiedKFold

skf = StratifiedKFold(n_splits=N)

for train_index, test_index in skf.split(...):

데이터를 K등분 하더라도 기본적으로 데이터 자체적으로 분포가 편향되어 (불균형) 있는 경우 학습이 무의미하다. (특정 데이터 폴드 세트에만 여러 레이블이 존재하고 나머지 데이터 폴드 세트에는 하나의 레이블만이 존재하는 경우)
이러한 불균형을 해결하기 위한 방법으로 Stratified K 폴드가 있다. 

- cross_val_score()
cross_val_score(estimator, X, y=None, scoring=None, cv=None, n_jobs=1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')
estimator : 회귀 및 분류 알고리즘 인스턴스
X : 피처 데이터 세트(학습)
y : 레이블 데이터 세트(테스트)
scoring : 예측 성능 평가 지표 (metrics)
cv : 교차 검증 폴드 수 (데이터 폴드 세트)
위에서 교차검증을 한 방법들을 보면 for loop를 iterative하게 순회히며 학습 및 예측을 진행했다. 이러한 일련의 과정들을 한번에 진행해주는 메소드이다.

- GridSearchCV
from sklearn.model_selection import GridSearchCV

params = {'..': [.., ..], '..': [.., ..]}

grid_dtree = GridSearchCV(estimator=clf, param_grid=params, scoring='accuracy', cv=K, refit=True)

estimator : 회귀 및 분류 알고리즘 인스턴스
param_grid : 하이퍼 파라미터 딕셔너리
scoring : 예측 성능 평가 지표
cv : 폴드 수
refit : 최적의 하이퍼 파라미터를 찾은 뒤 입력된 estimator 인스턴스 학습 여부

 하이퍼 파라미터(사람이 직접 세팅해야 하는 파라미터)는코드가 수행된 이후 직접 변경해야 했다. 하지만, 학습을 진행해볼 하이퍼 파라미터의 목록을 딕셔너리 형태로 인자로 넘겨서 각각의 케이스에 대해 교차검증과 학습을 진행하여 최적의 하이퍼 파라미터를 손쉽게 파악할 수 있는 API이다.
