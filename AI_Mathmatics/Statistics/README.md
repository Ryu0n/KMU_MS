# 통계학의 기본 개념
## 통계학 (Statistics)
데이터의 수집(collect), 구성(organization), 분석(analysis), 해석(interpretation),
표현(presentation)에 관한 학문

## 통계학의 분류
* 기술 통계학 (descriptive statistics)  
  수집된 데이터를 설명하기 위한 통계학 (해석단계)
* 추측 통계학 (inferential statistics)  
  해석을 통한 데이터를 토대로 추론하는 통계학 (추론단계)

## 개념 정의
* 모집단 (population)  
  어떤 질문이나 실험을 위해 관심의 대상이 되는 개체나 사건의 집합  
  ex) 전교학생의 키
* 모수 (parameter)  
  (모집단을 하나로 표현하기 위한) 모집단의 수치적인 특성  
  ex) 키의 평균, 분산, 표준편차 ..
* 표본 (sample)  
  모집단에서 선택된 개체나 사건의 집합  
  ex) 전교 남학생
  
보통 모수를 파악하기 위해 모집단을 전부 분석하는 것이 아니라 모집단으로부터 **표본을 추출하여 모수를 추론**한다.  

## 도수 (Frequency)
어떤 사건이 실험이나 관찰로부터 발생한 횟수  
ex) 전교생의 키를 분석할 때 160~170 사이의 학생이 몇 명이 존재하는지  

### 표현방법
* 도수분포표 (Frequency Distribution Table) - 질적 데이터  
  ![img.png](images/img.png)  
  각 범주의 데이터가 몇번 발생했는지를 표시  
* 막대그래프 (Bar graph) - 질적 데이터  
  ![img_1.png](images/img_1.png)  
  범주로 구분  
  ex) 남자와 여자, 소설책의 분류
* 히스토그램 (Histogram) - 양적 데이터  
  ![img_2.png](images/img_2.png)  
  ![img_3.png](images/img_3.png)  
  숫자의 **구간**으로 구분, 구간을 먼저 설정해야 한다.  
  ex) 남학생의 키
  
* 줄기-잎 그림 (Stem and Leaf Diagram) - 양적 데이터  
  ![img_4.png](images/img_4.png)  
  앞부분은 stem (구간의 역할을 하는 줄기), 뒷부분은 leaf (해당 구간의 세부데이터 역할을 하는 잎)  
  ex) 16이라는 구간은 18전까지를 의미한다. (1.6~1.7)

## 상대도수 (Relative Frequency)
![img_5.png](images/img_5.png)  
위 그림에서 도수의 총합은 54이다. 도수를 상대도수로 표현하면 다른 도수와의 비율을 상대적으로 파악하기 쉽다.

## 평균 (Mean)
![img_6.png](images/img_6.png)  
![img_7.png](images/img_7.png)  
평균은 **모평균**과 **표본평균**으로 나눌 수 있다. 
모평균은 모집단으로부터 추출한 평균값을 의미하고, 
표본평균은 모집단으로부터 추출한 표본집단의 평균값을 의미한다.

## 중앙값 (Median)
![img_9.png](images/img_9.png)  
평균값은 **극단적으로 크거나 작은 값에 영향을 많이 받는다.** 이러한 단점을 보완할 수 있는 개념이 중앙값이다.
데이터의 수가 짝수개일 경우 n/2번째 값과 n/2+1번째 값의 중앙값이 된다.  
데이터의 수가 홀수개일 경우 (n+1)/2번째 값이 된다.

## 분산 (Variance)
![img_10.png](images/img_10.png)
값이 어느정도 퍼저있는 지를 **산포**라고 표현한다. 산포를 정량적으로 표현할 수 있는 방법이 **분산**이다.  
표본분산에 n-1을 나누는 이유 : https://m.blog.naver.com/95khc/220282362093  

## 표준편차 (Standard Deviation)
![img.png](images/img_11.png)  

## 범위 (Range)
![img_1.png](images/img_12.png)  

## 사분위수 (Quartile)
![img_2.png](images/img_13.png)  
![img_3.png](images/img_14.png)  

## z-score
![img_4.png](images/img_15.png)

# 확률
![img.png](img.png)  
데이터를 토대로 추론을 할 때 그 추론의 정확성을 파악하기 위함이다.  

![img_1.png](img_1.png)  
사건은 표본 공간의 부분집합이다.  
(사건의 원소 수 / 표본공간의 원소 수) : **표본 공간의 모든 원소가 일어날 확률이 같은 경우**라는 전재가 깔려야 유의미한 공식이 된다.

![img_2.png](img_2.png)  
![img_3.png](img_3.png)

## 확률의 계산
![img_4.png](img_4.png)  
**조합**을 사용하여 경우의 수 계산을 편하게 한다.  

![img_5.png](img_5.png)  
ex) 1~10 까지의 공에서 두번을 뽑았을 때, 1과 3을 뽑을 확률 (1, 3으로 뽑든 3, 1로 뽑든 상관없음)
10C2

![img_6.png](img_6.png)  
![img_7.png](img_7.png)

> 검은공 하나, 흰공 하나일 확률은?  
(3C1 * 4C1) / 7C2  
> (검은공에서 뽑는 경우의수 * 흰공에서 뽑는 경우의수) / (전체에서 2개 뽑는 경우의수)

![img_8.png](img_8.png)  

## 덧셈법칙
![img_9.png](img_9.png)  
![img_10.png](img_10.png)  
![img_11.png](img_11.png)  
P(남자) = 0.4 / P(20세 미만) = 0.43 / P(남자 and 20세 미만) = 0.15  
P(남자 or 20세 미만)  
= P(남자) + P(20세 미만) - P(남자 and 20세 미만)  
= 0.4 + 0.43 - 0.15  
= 0.68

## 서로 배반
![img_12.png](img_12.png)  
집합 간에 겹치는 부분이 없는 경우 
**하나의 사건에 대해 공통분모가 없는 경우**

## 조건부 확률
![img_13.png](img_13.png)  
![img_14.png](img_14.png)  
표본공간의 변화 : 전체표본공간(1, 2, 3, 4, 5, 6) -> 4이상의표본공간(4, 5, 6)  
사건 A가 발생할 것을 전재로 깔기 때문에 분모에 P(A)가 온다.  
A와 B가 동시에 일어날 확률 / A가 일어날 확률

## 곱셈법칙
![img_15.png](img_15.png)  
P(남자) = 0.6 / P(남자 bar 축구) = 0.8  
P(남자 and 축구)  
= P(남자) * P(남자 bar 축구) = 0.8 * 0.6  
= 0.48

## 서로 독립
![img_16.png](img_16.png)  
**A가 일어났을 때 B가 일어나는 확률**이랑 **A가 일어나는 안일어나든 B가 일어날 확률**이랑 같음을 의미.  
**하나의 사건이 다른 사건에 영향을 주지 않음.**  
P(B bar A) = P(A and B) / P(A) = P(B)  
P(A and B) = P(A) * P(B)

## 여사건
![img_17.png](img_17.png)  
![img_18.png](img_18.png)  

## 확률의 분할법칙
![img_19.png](img_19.png)  
![img_20.png](img_20.png)  

## 베이즈 정리
![img_21.png](img_21.png)  
![img_22.png](img_22.png)  
![img_23.png](img_23.png)  
2살 이상인 동물을 선택했을 때 그것이 사자일 조건부확률  
사전확률 : P(A)  
사후확률 : P(A|B)  
사후확률과 사전확률의 관계를 정의하기 위한 개념.  
사전확률에 증거(Evidence)가 추가되며 확률이 갱신됨.

![img_24.png](img_24.png)  
![img_25.png](img_25.png)

## 확률 변수 (random variable)
![img_26.png](img_26.png)  
확률변수는 표본공간에서 랜덤하게 추출한 요소중 특정 조건을 만족하는 것(관계)을 정의해두는 것을 의미한다.  
**확률변수는 실수다.**

![img_27.png](img_27.png)  
이산확률변수 : 관계로 정의된 요소들의 값 범위(도메인)가 이산적으로 떨어져있는 경우 (불연속성)  
연속확률변수 : 관계로 정의된 요소들의 값 범위(도메인)가 연속적으로 구성되어 있는 경우

## 확률 분포 (Probability Distribution)
![img_28.png](img_28.png)  
![img_29.png](img_29.png)  
![img_30.png](img_30.png)  
![img_31.png](img_31.png)  
표본평균과 표본분산이 모평균과 모분산에 대응.

## 이산확률변수
![img_32.png](img_32.png)  
![img_33.png](img_33.png)  
![img_34.png](img_34.png)  
![img_35.png](img_35.png)  
![img_36.png](img_36.png)  
![img_37.png](img_37.png)  
![img_38.png](img_38.png)

## 결합확률 분포
![img_39.png](img_39.png)  
![img_40.png](img_40.png)  
주변확률 분포를 도출하려면 다른 확률변수를 무시하고 다 더하면 된다.  
예를 들어, X의 확률 분포를 구한다고 가정하면  
x = 0 : 0.1 + 0 = 0.1  
x = 1 : 0.2 + 0.4 = 0.6  
x = 2 : 0 + 0.3 = 0.3  

Y의 확률 분포를 구할 때는  
y = 0 : 0.1 + 0.2 + 0 = 0.3  
y = 1 : 0 + 0.4 + 0.3 = 0.7  

## 공분산
![img_41.png](img_41.png)  
두 개의 확률분포가 어떤 관계를 가지고 있는지 확인할 수 있다.  
(X - E(X))(Y - E(Y))가 양일 가능성이 높은 이유는 키가 크면 몸무게가 그에 비례하기 높을 가능성이 크기 때문이다. (키가 평균보다 클 경우)  
반면, (X - E(X))(Z - E(Z))가 양과 음이 될 가능성이 반반인 이유는 키와 성적은 관련이 없기 때문이다.  

![img_42.png](img_42.png)  
공분산의 값이 0에 가까울수록 두 확률변수는 관련이 없다.  
관련없는 두 확률변수의 편차의 곱(X - E(X))(Z - E(Z))(X - E(X))(Z - E(Z))은 양과 음이 될 가능성이 반반이기 때문에 평균은 0이 되기 때문이다.  

![img_43.png](img_43.png)  
![img_44.png](img_44.png)  
공분산은 확률변수의 크기가 급격하게 커지면 영향을 받을 수 있다. 
예를 들면, 위에 표는 X의 확률 변수는 0, 1, 2지만 0, 100, 200일 경우 1x100x0.4 + 1x200x0.3 ..  
이러한 영향을 없애주기 위해 일종의 정규화과정을 거쳐야 한다. 확률변수가 크면 표준편차도 크게 나올것이기 때문에 이러한 영향을 상쇄시켜줄 수 있다.  

![img_45.png](img_45.png)

# 확률분포
## 이항분포
![img_46.png](img_46.png)  
![img_47.png](img_47.png)  
![img_48.png](img_48.png)  
![img_49.png](img_49.png)

## 정규분포
![img_50.png](img_50.png)  
연속확률분포는 셀 수 없기 때문에 적분을 통해 도출된 면적을 확률로 해석한다.
![img_51.png](img_51.png)  
![img_52.png](img_52.png)  
확률밀도함수로써 가장 많이 사용되는 것이 정규분포이다. 해당 함수는 적분을 통해 확률을 계산하는것 보다는 표준정규분포표를 봐야한다.  
X~N(평균, 분산)  

![img_53.png](img_53.png)  
Z 정규화, X는 정규확률분포를 따르는 확률변수를 의미한다. 뮤는 평균, 시그마는 표준편차이다. Z 정규화를 하게되면 **평균이 0, 분산이 1**인 확률밀도함수(표준정규분포)로 변형된다.  
확률을 확인하기 위해 표준정규분포표를 참고하면 된다.  
ex) 0.75는 0.75보다 작을 확률을 의미한다.  

![img_54.png](img_54.png)  
![img_55.png](img_55.png)  
![img_56.png](img_56.png)  

## 이산확률분포 - 포아송(Poisson) 분포
![img_57.png](img_57.png)  
임의의 시공간 표본공간에서 발생하는 이벤트의 확률분포 (이산확률분포)  
**포아송 분포는 평균과 분산이 동일하다.**  

![img_58.png](img_58.png)  
![img_59.png](img_59.png)

## 연속확률분포 - 지수분포
![img_60.png](img_60.png)  
웹 사이트를 열고 한 시간동안 평균 3명이 오는데 반드시 20분 간격으로 1명씩 오는 것은 아니다.
경우에 따라 5분, 30분간격으로 올 수도 있다.  
람다가 3일 때 20분마다 한명이 오는것이기 때문에 1/3이 평균이 된다. (일반적으로 20분 간격 꼭은 아님.)  

![img_61.png](img_61.png)  

# 표본분포
![img_62.png](img_62.png)  
표본분포는 표본을 모집단으로부터 무엇을 추출하느냐에 따라 달라지기 떄문에 표본조사에는 **오차가 반드시 발생한다.**  

![img_63.png](img_63.png)  
표본을 추출하는 데에는 다음과 같은 방법들이 있다. 단순랜덤추출법은 말그대로 모집단중에서 임의의 원소를 난수표를 통해 선택하는 것이다.  

![img_64.png](img_64.png)  
표본을 추출하고 분석하여 모수(모평균, 모분산, 모비율 등)를 알아내야 한다. (표본조사를 통해 나온 통계량(평균과 분산)을 통해 모수(모평균과 모분산)을 예측)  

![img_65.png](img_65.png)  
표본조사를 통해 나온 통계량 또한 어떤 분포(**표본분포**)를 따른다.  

![img_66.png](img_66.png)  
**표본평균은 평균이 뮤(모집단의 평균)이고, 분산이 n분의 시그마 제곱(모집단의 분산)인 정규분포를 따른다.**  

![img_67.png](img_67.png)  
np.random.normal : normal distribution (평균 0, 분산 1인 정규분포), size=10 : 표본의 원소 10개 (n이 10)  
원소가 10개인 표준정규분포의 평균을 1만번 측정한 것의 평균을 재봤을 때 0, 0.1에 근사한 값이 나온다.

![img_68.png](img_68.png)  
이번에는 평균을 10, 분산을 3으로 한 경우이다. 표준정규분포의 평균은 10, 분산은 0.9 (3*3/10)  

![img_69.png](img_69.png)  
모집단의 분포가 정규분포가 아닌 다른 분포일 수도 있다. 이럴 때 사용할 수 있는 정리가 **중심극한정리**이다.
**n이 충분히 큰 경우에는 표본분포는 근사적으로 정규분포를 따를 수 있다**는 내용이 중심극한정리이다.  

![img_70.png](img_70.png)  
np.random.normal이 아닌 np.random.rand일 경우 Uniform Distribution을 따르게 된다.
Uniform Distribution은 0~1 사이의 숫자를 리턴한다. np.random.rand(n)의 경우 0~1사이의 숫자 n개를 리턴한다.
np.random.rand의 리턴 타입은 numpy array이기 때문에 *10 을 하게 되면 리스트와는 다르게 브로드캐스팅 연산이 적용된다.
(0~10), bins는 몇개의 구간으로 쪼갤건지 나타내는 인자이다.  
uniform distribution의 분산값 : (b-a)^2 / 12
표본평균 : 5, 표본분산 : 8.3(시그마 제곱) / 3(n) = 2.7..  
현재는 n이 3이라 넓게 퍼져있지만 30이후로부터는 평균값에 값들이 일관되게 물린다.

![img_71.png](img_71.png)  
uniform distribution처럼 가운데가 아닌 한쪽으로 기울어진 경우는 어떨까? (지수분포)  
포아송분포의 평균 : 1/3, 포아송본포의 분산 : 1/3  
지수분포의 평균 : 1/(포아송분포의 평균), 지수분포의 분산 : 1/(포아송분포의 평균)^2  

![img_72.png](img_72.png)  
모집단(지수분포)의 분산 : 9, 표본분산 : 9/n = 9/2 = 4.5  

![img_73.png](img_73.png)  
n을 늘리면 다음과 같은 결과가 나온다.

# 추정
우리의 목적은 전수조사를 할 수 없기 때문에 표본의 특성을 통해 모집단의 특성 (모평균, 모분산 등..)을 파악하는 것이다.  

## 모평균의 추정
![img_74.png](img_74.png)  
정규분포를 따르는 경우, n개의 원소들의 평균을 내면 표본 평균을 구할 수 있다.
하지만, 여기서 고려해야 할 사항이 두 가지가 있다.  
첫 번째는 표본이기 때문에 정확한 모평균을 추정하는 것은 아니라는 점 (신뢰구간을 정의해야함)  
두 번째는 정규분포를 따르지 않는 경우 충분히 많은 표본(n>=30)을 통해 **중심극한정리**에 의해 정규분포에 근사시켜야 하는 것이다.  

추정에는 **점 추정**과 **구간 추정** 두 가지 종류가 있다.  

## 모평균 - 점 추정
![img_75.png](img_75.png)  
표본을 어떻게 선택하느냐에 따라 다른 표본평균이 나오기 때문에 점 추정만 가지고 모평균을 추정하기에는 신빙성이 부족하다.

## 모평균 - 구간 추정
![img_76.png](img_76.png)  
우선 표본분포는 ![img_77.png](img_77.png) 다음과 같은 평균과 분산을 따르는 것을 상기해야 한다.
점 추정만으로는 정확한 모평균을 측정하기 힘들기 때문에 구간 추정도 병행해야 한다.  

![img_78.png](img_78.png)
![img_79.png](img_79.png)
![img_80.png](img_80.png)
![img_81.png](img_81.png)
![img_82.png](img_82.png)  
![img_83.png](img_83.png)

## 모비율 - 점 추정
![img_84.png](img_84.png)  
![img_85.png](img_85.png)  

## 모비율 - 구간 추정
![img_86.png](img_86.png)  
모비율 같은 경우에는 특정 집단에 속하냐 안속하냐를 판단하기 때문에 **이항분포의 평균과 분산** 따르게 된다.
물론, **중심극한정리**에 의해 정규분포를 따른다.  

![img_87.png](img_87.png)  
![img_88.png](img_88.png)
![img_89.png](img_89.png)
![img_90.png](img_90.png)
![img_91.png](img_91.png)

# 검정
![img_92.png](img_92.png)  
특정 가설을 세운 후, 새로운 사실을 통해 가설이 맞는지를 검사하는 과정을 **가설 검정**이라고 한다.
mu0는 기존에 알려진 모평균을 의미하고, mu는 실제 모평균을 의미한다.  

![img_93.png](img_93.png)  
귀무 가설(歸無假說, 영어: null hypothesis, 기호 H0) 또는 영 가설(零假說)은 통계학에서 **처음부터 버릴 것을 예상하는 가설**이다. 
**차이가 없거나 의미있는 차이가 없는 경우의 가설**이며 이것이 맞거나 맞지 않다는 통계학적 증거를 통해 증명하려는 가설이다. 
예를 들어 범죄 사건에서 용의자가 있을 때 형사는 이 용의자가 범죄를 저질렀다는 추정인 대립가설을 세우게 된다. 
이때 귀무가설은 용의자는 무죄라는 가설이다.
통계적인 방법으로 가설검정(hypothesis test)을 시도할 때 쓰인다. 로널드 피셔가 1966년에 정의하였다.  

![img_94.png](img_94.png)  
귀무가설이 참이려면, 표본평균이 낮아야 하는데 이것이 낮은지 높은지를 정하는 기준점이 필요하다.
그래서 우리는 유의수준(alpha)이라는 개념을 도입하여 이보다 낮으면 낮다고 판단한다.
