데이터 전처리에는 두 가지 방법이 존재한다.
1. 데이터 인코딩
2. 피처 스케일링 및 정규화

먼저 "데이터 인코딩"부터 알아보려 한다. 데이터 인코딩은 두 가지 방법이 있다.
1. 레이블 인코딩
2. 원-핫 인코딩

레이블 인코딩은 "각각의 클래스별로 분류할 수 있는 숫자를 매핑"해주는 역할을 한다. 
그러나 이 숫자들은 누적해서 점점 증가하기 때문에 가중치가 부여되는 현상이 발생할 수도 있다.
그래서 우리는 원-핫 인코딩을 통해 레이블 인코딩의 결과를 0과 1을 요소로 하는 벡터화를 진행하여
이러한 문제점을 해결한다.

다음으로는 "피처 스케일링 및 정규화"의 대표적인 두 가지 방법에 대해 알아보겠다.
1. StandardScaler
2. MinMaxScaler

StandardScaler는 데이터가 가우시안 정규분포(평균 0, 분산 1)을 따르도록 Z 표준화를 한다. (Z = 편차 / 표준편차)
주로 정규분포를 따른다고 가정하고 동작하는 알고리즘인 SVM, Linear Regressoin, Logistic Regression에서 필요하다.
MinMaxScaler는 이름에서 알 수 있듯이 최소와 최대값을 지정하는 스케일링이다. (X' = Xi - Min(X) / Max(X) - Min(X))

=============================================================================

평가
분류(Classification)의 성능 평가 지표로써 다음과 같이 두 가지 방법이 존재한다.
1. 정확도 (Accuracy)
2. 오차행렬 (Confusion Matrix)

* 정확도
[정확도 = 예측 결과가 동일한 데이터 건수 / 전체 데이터 건수]
정확도는 매우 직관적인 지표이다. 하지만, 불균형한 레이블 데이터 세트에서는 적절하지 않다.
그 이유는 예시를 들어보겠다. 100개의 데이터중 True가 90개, False가 10개가 있다고 가정하자.
이러한 경우 무조건 결과를 True로 반환하는 경우 정확도는 90%가 된다. 
정확도가 가지는 한계점을 극복하기 위해 여러가지 분류 지표를 적용해야 한다.

* 오차행렬
예측은 긍정을 Positive, 부정의 경우는 Negative로 분류할 수 있다.
긍정으로 분류한 결과가 맞은 경우와 틀린 경우를 TP (True Positive), FP (False Positive)로 분류할 수 있고,
부정으로 분류한 결과가 맞은 경우와 틀린 경우를 TN (True Negative), FP (False Negative)로 분류할 수 있다.
위와 같은 네 가지 케이스로 분류한 것을 "오차 행렬"로 정의한다. 

정확도는 오차 행렬로 공식화를 하면 [(맞게 예측한 경우) / (틀리게 예측한 경우) = (TP + TN) / (TP + FP + TN + FN)] 이다.
만약, 450개의 데이터 중 405개의 Nagative와 45개의 Positive가 있을 때, 무조건 Negative로 분류하는 모델이 있다고 하면
(TP + TN) / (TP + FP + TN + FN) = (0 + 405) / (0 + 0 + 405 + 45) = 0.9로 매우 높은 신뢰성 없는 정확도를 보인다.

* 재현율 (Recall) = 민감도, TPR (True Positive Rate), 정밀도 (Precision)
재현율과 정밀도는 Positive 예측 성능에 초점을 맞춘 평가 지표이다.
재현율 = TP / (FN + TP) = (Positive를 정확하게 예측한 경우) / (실제로 Positive인 경우)
정밀도 = TP / (FP + TP) = (Positive를 정확하게 예측한 경우) / (Positive로 예측한 경우)

재현율이 중요한 지표인 경우 : 실제 Positive를 Negative로 잘못 판단하면 큰 문제인 경우 -> 실제 Positive (TP + FN), Negative로 잘못 판단 (FN)
ex) 암 양성을 음성으로 판단하면 위험한 경우
정밀도이 중요한 지표인 경우 : 실제 Negative를 Positive로 잘못 판단하면 큰 문제인 경우 -> 실제 Negative (TN + FP), Positive로 잘못 판단 (FP)
ex) 스팸 음성(일반 메일)을 양성(스팸 메일)으로 판단하여 못읽는 경우

=> 재현율과 정밀도 모두 TP를 높이는데 초점이 맞춰져 있지만, 재현율은 "FN을 낮추는 데에", 정밀도는 "FP를 낮추는 데에" 초점이 맞춰져 있다.

* 재현율과 정밀도의 트레이드 오프
Threshold : 분류(Class)의 결정 임계값
ex) 임계값이 0.5 (50%)라고 가정하자. 특정 데이터의 Positive일 확률이 90%, Negative일 확률이 10%일때 Positive가 임계값보다 높으므로 최종적으로 Positive라고 판단한다.
ex) 임계값을 0.4로 낮추면 최종적으로 Positive로 예측할 확률은 높아진다.
이처럼 임계값을 낮출수록 Positive로 예측할 확률이 높아지기 때문에 (TP + FP)는 절대적으로 커지고, (TN + FN)은 작아진다.
"""따라서 재현율은 높아지고 (분자인 TP는 증가하고 분모인 FN은 감소), 정밀도는 낮아진다. (분모인 FP가 같이 증가하기 때문에)"""

* 정밀도가 100%가 되는법
정밀도의 공식을 상기시켜보면 TP / (TP + FP)이다. 고로 FP를 0으로 만들면 된다. 즉, 확실한 경우에만 Positive로 예측하고, 그 외의 경우는 전부 Negative로 예측한다.

* 재현율이 100%가 되는법
재현율의 공식을 상기시켜보면 TP / (TP + FN)이다. 고로 FN을 0으로 만들면 된다. 즉, 모든 데이터를 Positive로 예측하면 된다. (TP, FP에 모든 데이터가 몰릴것이다.)

* F1 스코어
"정밀도와 재현율의 조화 평균"을 의미한다.
F1 = 2*(정밀도 * 재현율) / (정밀도 + 재현율)

* ROC 곡선
ROC 곡선은 FPR (False Positive Rate)이 변할 때 TPR (True Positive Rate)이 어떻게 변하는지를 나타내는 곡선이다.
TPR (민감도) = TP / (TP + FN)
TNR (특이성) = TN / (TN + FP)
FPR = FP / (TN + FP) = 1 - TNR

ROC 곡선을 그릴 때에는 X축에는 FPR, Y축에는 TPR이 온다.
ROC 곡선을 그리기 위해서는 FPR을 0부터 1로 변화시키면서 그릴 수 있다.
FPR을 0으로 만드려면 분류 결정 임계값(Threshold)를 1로 바꾸면 된다. (전부 Positive로 예측)
그리고 서서히 임계값을 0으로 줄여나가면 된다.

ROC 곡선은 볼록한 형태를 띄울수록 성능이 좋다.
