* 앙상블
여러 개의 분류기를 결합하는 기법을 의미한다.

이미지, 영상, 음성과 같은 비정형 데이터의 분류는 딥러닝, 정형 데이터의 분류는 앙상블 기법이 좋은 성능을 나타낸다.

* 앙상블 종류
- Voting
분류기의 예측 결과의 다수결에 의한 방법으로, 여러 알고리즘들을 결합하며 전체 데이터셋에 대해 수행한다.

- Bagging
동일한 알고리즘들을 결합하며, Bootstraping(복원추출)을 통한 샘플링을 통해 얻은 데이터셋들로 다수결을 진행한다.
ex) RandomForest

- Boosting
분류기를 순차적으로 학습하며, 앞에서 분류기가 틀린 데이터에 대해 뒤에 있는 분류기가 가중치를 두어 학습한다.
ex) XGBoost, LightGBM

- Stacking
여러 분류기가 도출한 결과값을 학습 데이터로 삼아 다른 분류기에 학습. (메타 모델)

* 보팅 기법
하드 보팅과 소프트 보팅이 존재한다.
하드 보팅은 단순히 결과값만을 가지고 판단하고, 소프트 보팅은 각 클래스별 확률을 클래스별로 평균을 내어 판단한다.

* 랜덤 포레스트
동일한 분류기를 여러개 결합한 배깅 방식중 대표적인 방법이며, Decision Tree를 base estimator로 삼은 것이다.

* AdaBoost
iteration을 반복하며, 이전 iteration에서 잘못 분류한 데이터에 가중치를 두어 현재 iteration에서 분류한다.
그리고, 모든 iteration의 분류 경계선의 합집합을 통하여 분류한다.

* Gradient Boost
Gradient Descent + Boosting을 의미한다.
residual (실제값 - 예측값)을 최소화 하는 방향성을 가진다.
미분을 통해 나온 값의 반대 방향으로 이동.
오버피팅을 방지하기 위해 subsampling(전체 데이터 학습 x), early stopping(iteration을 끝까지 수행 x) 등의 방법이 존재한다.
